\documentclass{unswmaths}

\usepackage{unswshortcuts}

\begin{document}

\subject{Measure Theory}
\author{Edward McDonald}
\title{Assignment 2}
\studentno{3375335}


\setlength\parindent{0pt}


\newcommand{\Bor}{\mathcal{B}}
\newcommand{\sdiff}{\bigtriangleup}
\newcommand{\Expect}{{\rm I\kern-.3em E}}

\unswtitle{}


\section*{Question 1}
For this question, let $\mu$ and $\nu$ be probability measures
    on $(\Rl^d,\Bor(\Rl^d))$.

\begin{lemma}
    The function $x\mapsto \nu(B-x)$ is $\Bor(\Rl^d)$
    measurable for any $B \in \Bor(\Rl^d)$.
\end{lemma} 
\begin{proof}
    Let $B \in \Bor(\Rl^d)$ and $s(x) = \nu(B-x)$. Then,
    \begin{align*}
        s(x) &= \int_{\Rl^d} \chi_{B-x}\;d\nu\\
        &= \int_{\Rl^d} \chi_B(y+x)\;d\nu(y).
    \end{align*}
    The function $(x,y)\mapsto \chi_{B}(y+x)$
    is a composition of a continuous function, $(x,y)\mapsto y+x$
    and a measurable function $x\mapsto \chi_B(x)$. 
    Hence the function $(x,y)\mapsto \chi_{B}(y+x)$
    is $\Bor(\Rl^d)\otimes\Bor(\Rl^d)$ measurable,
    and so by Tonelli's theorem $s$ is $\Bor(\Rl^d)$
    measurable.
\end{proof}

\begin{lemma}
    The convolution measure $\mu\star\nu(B) = \int_{\Rl^d} \nu(B-x)\;d\mu(x)$
    is well defined and finite.
\end{lemma}
\begin{proof}
    Since $\mu\star\nu(B)$ is defined as an integral of a positive
    measurable function, the integral exists. Since $\nu(B-x) \leq 1$,
    we have $\mu\star\nu(B) \leq 1$.
\end{proof}

\begin{theorem}
    If there exists some bounded $F$
    such that $\mu\star\nu(F) = 1$, then there are bounded
    sets $G$ and $H$ such that $\mu(G) = 1$ and $\nu(H) = 1$.
    Similar results hold where ``bounded" is replaced with
    ``finite" or ``countable".
\end{theorem}
\begin{proof}
    Suppose that there exists a bounded set $F \in \Bor(\Rl^d)$
    such that $\mu\star\nu(F) = 1$, but for any bounded
    set $B$, $\mu(B),\nu(B) < 1$. Then,
    \begin{align*}
        \mu\star\nu(F) &= \int \nu(F-x) \;d\mu(x)\\
        &< \int 1\;d\mu\\
        &= 1.
    \end{align*}
    since $F-x$ is bounded for any $x$. This is a contradiction.
    Hence we must have
    that $\nu$ attains the value $1$ on some bounded set.
    
    By symmetry, $\mu$ must also take the value $1$ on some bounded set.
    
    An identical argument holds if ``bounded" is replaced by ``finite" or
    ``countable".
\end{proof}

\section*{Question 2}
For this question, $\mu$ and $\nu$ are $\sigma$-finite positive measures
on a measurable space $(\Omega,\mathcal{F})$.
\begin{theorem}
    The following are equivalent:
    \begin{enumerate}
        \item{} $\mu$ and $\nu$ have exactly the same null sets.
        \item{} $\mu \ll \nu$ and $\nu \ll \mu$.
        \item{} There is an $\mathcal{F}$-measurable
        function $g$ with $0 < g < +\infty$ such that $\nu(A) = \int_A g\;d\mu$
        for all $A \in \mathcal{F}$.
    \end{enumerate}
\end{theorem}
\begin{proof}
    First we prove $(1)\Rightarrow(2)$.
    
    Assume that $\mu$ and $\nu$ have exactly the same null sets. 
    Then if $\mu(A) = 0$, then $\nu(A) = 0$.
    That is $\nu \ll \mu$. Similarly, $\mu \ll \nu$.
    
    Now we prove $(2)\Rightarrow(3)$. 
    
    Assume that $\nu \ll \mu$. 
    
    By the Radon-Nikodym Theorem,
    there is an $\mathcal{F}$-measurable function $g$
    such that $\nu(A) = \lambda(A)+\int_A g\;d\mu$,
    where $\lambda$ is a measure mutually singular to $\mu$. Suppose
    that $\mu(A) = 0$, then $\nu(A) = 0$ by assumption, hence $\lambda(A) = 0$.
    Thus $\lambda \ll \mu$ and $\lambda \bot \mu$, so $\lambda = 0$.
    
    Suppose that $g = \infty$ only on a null set. Then we can modify
    $g$ to $g = 0$ on this set since $g$ is determined only up
    to $\mu$-almost everywhere equivalence.
    
    Suppose there is some set $A$ with $\mu(A) > 0$ and $g(A) = \{\infty\}$.
    
    Since $\nu$ is $\sigma$-finite, there exists $B$ with $\nu(B) < \infty$
    and $\nu(A\cap B) > 0$.
    
    Hence $g(A\cap B) = \{\infty\}$, and we cannot have $\mu(A\cap B) = 0$
    because then $\nu(A\cap B) = 0$.
    
    But then $\nu(A\cap B) = \infty$, but this is a contradiction.
    Hence $g < \infty$ $\mu$-almost everywhere.
    
    Now suppose there is some set $C$ with $\mu(C) > 0$
    and $g(C) = \{0\}$. Hence $\nu(C) = 0$, but since $\mu \ll \nu$
    this is a contradiction.
    
    Now we prove that $(3)\Rightarrow(1)$.
    
    Suppose that $\mu(A) = 0$. Then clearly since $\nu(A) = \int_A g\;d\mu(A)$,
    we have $\nu(A) = 0$.
    
    Now suppose that $\nu(A) = 0$. Now,
    \begin{equation*}
        \nu(A) \geq \frac{1}{n}\mu(A\cap g^{-1}([1/n,\infty))
    \end{equation*}
    Hence $\mu(A\cap g^{-1}([1/n,\infty)) = 0$. But since $g > 0$, we
    have 
    \begin{equation*}
        \mu(A) = \lim_{n\rightarrow\infty} \mu(A\cap g^{-1}([1/n,\infty)).
    \end{equation*}
    Hence $\mu(A) = 0$. Thus $\mu$ and $\nu$ have the same null 
    sets so $(1)$ is proved.
\end{proof}

\begin{theorem}
    Suppose that $\mu$ is a $\sigma$-finite positive measure on $(\Omega,\mathcal{F})$. Then there is a finite positive measure $\nu$
    on $(\Omega,\mathcal{F})$ such that $\nu \ll \mu$ and $\mu \ll \nu$.
\end{theorem}
\begin{proof}
    Suppose that $\{A_k\}_{k=1}^\infty$ is a disjoint sequence of sets
    with $A = \bigcup_k A_k$ and $0 < \mu(A_k) < \infty$. This can be chosen
    since $\mu$ is $\sigma$-finite.
    
    Now define,
    \begin{equation*}
        \nu(A) = \sum_{k=1}^\infty \frac{1}{2^k \mu(A_k)}\mu(A\cap A_k)
    \end{equation*}
    for $A \in \mathcal{F}$.
    This sum converges since each term is bounded by $1/2^k$, so the sum
    is bounded by a geometric series.
    
    We wish to show that $\nu$ is a probability measure
    on $(\Omega,\mathcal{F})$ and than $\mu \ll \nu$ and $\nu \ll \mu$. 
    
    Note that $\nu(\Omega) = 1$ and $\nu(\emptyset) = 0$.
    
    Suppose that $\{B_k\}_{k=1}^\infty$ is a disjoint sequence of sets
    in $\mathcal{F}$. Then
    \begin{equation*}
        \nu(\bigcup_k B_k) = \sum_{j=1}^\infty \sum_{k=1}^\infty \frac{1}{2^j \mu(A_j)}\mu(B_k\cap A_j)
    \end{equation*}
    Then since this is a sum of positive numbers, we can change the order
    of summation by Tonelli's theorem,
    \begin{equation*}
        \nu(\bigcup_k B_k) = \sum_{k=1}^\infty \nu(B_k).
    \end{equation*}
    Hence $\nu$ is countably additive, so is a measure on $(\Omega,\mathcal{F})$.
    
    Now we wish to show that $\nu \ll \mu$. Suppose that $\mu(A) = 0$.
    Then clearly $\mu(A_k \cap A) = 0$ for all $k$, so $\nu(A) = 0$. 
    Thus $\nu \ll \mu$.
    
    Now to show that $\mu \ll \nu$, let  
    $\nu(A) = 0$, then $\mu(A_k \cap A) = 0$ for all $k$. Hence,
    \begin{equation*}
        \mu(A) = \sum_{k=1}^\infty \mu(A_k\cap A) = 0.
    \end{equation*}
    Thus $\mu \ll \nu$. 
\end{proof}

\section*{Question 3}
For this question, $X$ is a $d$-dimensional random vector with law
$\mu$ and characteristic function $\hat{\mu}(u)$.
\begin{lemma}
    The characteristic function of $cX$ is $\hat{\mu}(cu)$,
    for any $c \in \Rl$.
\end{lemma} 
\begin{proof}
    This is a simple computation. By definition, the characteristic
    function of $cX$ is
    \begin{equation*}
        \Expect(e^{i\langle u,cX\rangle}
    \end{equation*}
    But since $\langle u,cX\rangle = \langle cu,X\rangle$, this is simply
    $\hat{\mu}(cu)$.
\end{proof}

\begin{theorem}
    If $X$ has moments up to order $n$, then $\hat{\mu}$ is differentiable
    at $0$ up to $n$th order, and $\frac{\partial^\alpha}{\partial u^\alpha}\hat{\mu}(u)|_{u=0} = i^{|\alpha|}\Expect(X^\alpha)$ for multi-indices $\alpha$, with
    $|\alpha| \leq n$.
\end{theorem}
\begin{proof}
    
    Suppose that $X$ has moments up to order $n$. Then we can say that,
    \begin{equation*}
        \frac{\partial}{\partial u_j} \Expect(e^{i\langle u,X\rangle}) = i\Expect(X_je^{i\langle u,X\rangle})
    \end{equation*}
    by the Dominated convergence theorem, since $\Expect(|X_j|) < \infty$. Hence,
    by induction,
    \begin{equation*}
        \frac{\partial^\alpha}{\partial u^\alpha}\Expect(e^{i\langle u,X\rangle}) = i^{|\alpha|} \Expect(X^\alpha e^{i\langle u,X\rangle}).
    \end{equation*}
    for all multi-indices $\alpha$ with $|\alpha| \leq n$ by the Dominated
    convergence theorem. This shows that the derivative exists.
    
    So we simply evaluate this at zero to obtain the required result.
\end{proof}    
Now we let $X$ be a random variable with Lebesgue density
\begin{equation*}
    f(x) = \frac{C}{(1+x^2)\log(e+x^2)}
\end{equation*}
for some normalising constant $C > 0$. Let $\hat{\mu}$ be the
characteristic function of $X$.

\begin{lemma}
    $\Expect(X)$ is not defined. That is, $X$ does not have moments up
    to order $1$.
\end{lemma}
\begin{proof}
    We have
    \begin{equation*}
        \frac{C}{(1+x^2)\log(e+x^2)}\leq \frac{C}{1+x^2}.
    \end{equation*}
    But the integral
    \begin{equation*}
        \int_{[0,\infty)} \frac{x}{1+x^2}\;d\lambda(x)
    \end{equation*}
    where $\lambda$ is Lebesgue measure is infinite, since
    $x/(1+x^2)$ has antiderivative $(1/2)\log(1+x^2)$, which is an unbounded function.
    Hence,
    \begin{equation*}
        \int_{[0,\infty)} \frac{Cx}{(1+x^2)\log(e+x^2)}\;d\lambda(x)
    \end{equation*}
    is infinite, so $\Expect(X)$ is not defined.
\end{proof}
    
\begin{lemma}
    $\hat{\mu}$ is differentiable at $0$.
\end{lemma}
\begin{proof}
    
\end{proof}

\section*{Question 4}
For this question, $\mu$ is the binomial distribution $\mathrm{Bin}(n,p)$,
and $\nu$ is the Poisson distribution with mean $\lambda > 0$.

\begin{lemma}
    The characteristic function of a Bernoulli random variable
    with probability $p$ is
    \begin{equation*}
        1-p+pe^{iu}
    \end{equation*}
\end{lemma}
\begin{proof}
    This is a simple computation, if $X$ takes the value $1$ with probability
    $p$ and $0$ with probability $1-p$, then
    \begin{equation*}
        \Expect(e^{iuX}) = 1-p+pe^{iu}.
    \end{equation*}
\end{proof}
\begin{lemma}
    $\hat{\mu}(u) = (1-p+pe^{iu})^n$.
\end{lemma}
\begin{proof}
    A sum of $n$ independent Bernoulli random variables with
    probability $p$ is $\mathrm{Bin}(n,p)$ distributed. So,
    \begin{equation*}
        {\mu} = {\mathrm{Bern}(p)}^{\star n}
    \end{equation*}
    
    Hence,
    \begin{equation*}
        \hat{\mu}(u) = (1-p+pe^{iu})^n.
    \end{equation*}
\end{proof}



\begin{lemma}
    $\hat{\nu}(u) = \exp(\lambda(e^{iu}-1))$.
\end{lemma}
\begin{proof}
    We can compute,
    \begin{equation*}
        \hat{\nu}(u) = \sum_{k=0}^\infty \frac{e^{iuk}e^{-\lambda}\lambda^k}{k!}
    \end{equation*}
    So we write this as,
    \begin{align*}
        \hat{\nu}(u) &= \sum_{k=0}^\infty e^{-\lambda} \frac{(e^{iu}\lambda)^k}{k!}\\
        &= e^{-\lambda} \exp(\lambda e^{iu})\\
        &= \exp(\lambda(e^{iu}-1)).
    \end{align*}
\end{proof}

\begin{lemma}
\label{stuart}
    Suppose that $q_n \rightarrow \lambda \in \Cplx$ is a sequence of complex
    numbers. Then
    \begin{equation*}
        \lim_{n\rightarrow\infty} \left(1+\frac{q_n}{n}\right)^n = e^{\lambda}
    \end{equation*} 
\end{lemma}
\begin{proof}
    Fix $n$ large enough such that $|q_n|/n < 1/2$.
    
    Since $q_n$ is a convergent sequence, it is bounded. Let $M$
    be large enough such that $|q_n| < M$ for all $n$.
    
    Re-write $\left(1+\frac{q_n}{n}\right)^n$ as $\exp(n\Log(1+\frac{q_n}{n}))$.
    
    The branch of the logarithm taken here is complex differentiable
    in the set $\Cplx\setminus(-\infty,0]$. Since $|q_n|/n < 1$, the above is valid.
    
    So it is sufficient to show that,
    \begin{equation*}
        \lim_{n\rightarrow\infty} n\Log\left(1+\frac{q_n}{n}\right) = \lambda
    \end{equation*}
    
    The $z\mapsto \Log(1+z)$ function is complex differentiable in the unit disc,
    and has a power series representation 
    \begin{equation*}
        \Log(1+z) = \sum_{k=1}^\infty (-1)^{k-1}\frac{z^k}{k}
    \end{equation*}
    which converges uniformly on compact subsets of the open unit disc $\{z\in \Cplx\;:\;|z| < 1\}$.
    
    Now, since $|q_n|/n < 1$, we have
    \begin{equation*}
        n\Log(1+\frac{q_n}{n}) = q_n+\sum_{k=2}^\infty (-1}^{k-1}\frac{q_n^k}{kn^{k-1}}
    \end{equation*}
    
    Now we consider the tail of the left hand side, let
    \begin{equation*}
        L_n := \sum_{k=2}^\infty (-1)^{k-1} \frac{q_n^k}{kn^{k-1}}
    \end{equation*}
    
    By the triangle inequality,
    \begin{equation*}
        |L_n| \leq \sum_{k=2}^\infty \frac{M^k}{kn^{k-1}}
    \end{equation*}
    Thus,
    \begin{align*}
        |L_n| &\leq M\sum_{k=1}^\infty \left(\frac{M}{n}\right)^k\\
        &= M\frac{M/n}{(1-M/n)}
    \end{align*}
    Hence, $L_n\rightarrow 0$ as $n\rightarrow\infty$.
    Thus, the limit
    \begin{equation*}
        \lim_{n\rightarrow\infty} n\Log(1+\frac{q_n}{n})
    \end{equation*}
    exists, and equals $\lim_{n\rightarrow\infty}q_n = \lambda$.
    
    Hence, the limit
    \begin{equation*}
        \lim_{n\rightarrow\infty}\left(1+\frac{q_n}{n}\right)^n
    \end{equation*}
    exists, and equals $e^\lambda$.
\end{proof}

Now we let $\{p_n\}_{n=1}^\infty$ be a monotone decreasing sequence, such
that $np_n \rightarrow \lambda$. We let $\mu_n = \mathrm{Bin}(n,p_n)$.
\begin{theorem}
    There is weak convergence, $\mu_n\rightarrow\nu$.
\end{theorem}
\begin{proof}
    By L\'evy's continuity theorem, it is sufficient to show pointwise convergence
    of characteristic functions, $\hat{\mu}_n(u)\rightarrow \hat{\nu}(u)$
    for all $u$. That is, we must show
    \begin{equation*}
        \lim_{n\rightarrow\infty} (1-p_n+p_ne^{iu})^n = \exp(\lambda(e^{iu}-1)).
    \end{equation*}    
    
    Rewrite $\hat{\mu}_n(u)$ as
    \begin{equation*}
        \left(1+\frac{np_n(e^{iu}-1)}{n}\right)^n
    \end{equation*}
    Now by lemma \ref{stuart}, we see
    \begin{equation*}
        \lim_{n\rightarrow\infty} \hat{\mu}_n(u) = \exp(\lambda(e^{iu}-1)).
    \end{equation*}
    Thus the result follows.
\end{proof}



\end{document}
